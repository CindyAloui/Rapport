

% Les packages utilise's ci-dessous le sont a` titre indicatif ;
% vous pouvez les changer a` votre convenance.

% Le type de document: article, rapport...
\documentclass[a4paper]{report}

% Mettre les diffe'rents packages et fonctions que l'on utilise
%\usepackage[english]{babel}
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphics,color}

\renewcommand\thesection{\arabic{section}}


% Commenter l'une de ces deux lignes
%\RequirePackage[applemac]{inputenc}
\RequirePackage[latin1]{inputenc}

\begin{document}


%----------- A   C O M P L E T E R   P A R   L E S   A U T E U R S ------------


% Titre du rapport
\def\TitreRapport{
	Learning noun countability using minimally supervised (deep) learning
}

% Pre'nom et nom dde l'auteur
\def\NomsAuteurs{
    Cindy Aloui
}

% Date du rapport (dans la me^me langue que le titre)
\def\DateRapport{
    25 mai 2018
}

% Nom des encadrants
\def\Encadrants{
    \textbf{Encadrant(s)} \\
	Carlos Ramisch et Alexis Nasr (co-encadrant)
}
% Nom du laboratoire
\def\Labo{
    LIF
}



% Re'sume' en franc,ais avec mots-cle's
\def\ResumeFrancais{
    R\'esum\'e en fran\c{c}ais obligatoire.
    \\[2mm]
    {\bf Mots-cl\'es : } mot-cl\'es  obligatoires.
}


\thispagestyle{empty}
\begin{center}
\baselineskip=1.3\normalbaselineskip
{\bf\Large \TitreRapport}\\[8mm]
{\bf\large \NomsAuteurs}\\[1mm]
{\Labo}\\[4mm]
\Encadrants\\[10mm]

{\bf R\'esum\'e}
\end{center}

\ResumeFrancais\\[4mm]

\newpage

%-------------------- T E X T E   D U   R A P P O R T -------------------------

\section{Introduction}

A faire.

\section{État de l'art}

A faire

\section{Description des données}

    Comme dis précédemment, nous souhaitons résoudre ce problème avec un minimum de supervision. Nous avons donc décidé d'utiliser pour l'entraînement seulement une liste de 200 mots typiquement massif et une liste de 200 mots typiquement comptable et du corpus frWaC qui a était annoté par le TreeTagger qui nous donne pour chaque mot sa forme lemmatisé et sa partie de discours.
    
     Dans un premier temps nous avons séparé ces listes en un ensemble de mots pour l'entraînement et un autre pour le test (100 mots comptable et 100 mots massifs pour l'entraînement et la même chose pour le test).
      
	Dans un second temps, nous avons choisi aléatoirement 100 noms qui apparaissent dans le frWaC et ensuite choisi à nouveau aléatoirement pour chacun de ces mots 100 phrases où il apparaît. Nous avons donné cet ensemble de phrases à une linguiste qui pour chaque mot à annoté 50 des phrases extraite et à indiqué si ce nom dans ce contexte précis est plutôt massif, comptable ou ni l'un ni l'autre.\\
\\
\textbf{Exemple :} 
\begin{center}
\emph{C Le [[ balai ]] est tombé dans un trou de plusieurs mètres de profondeur .} 
\end{center} Pour cette phrase le balai dans ce contexte a était annoté comptable.\\

Ces 5000 phrases vont nous servir lors de l'évaluation de notre classifieur. 

\section{Nom à trouver}

 Pour réaliser la tâche de classification massif/comptable nous avons penser à trois approches différentes : 
\begin{itemize}
\item classifier le nom hors contexte en fonction des contextes dans lequel il apparaît (par exemple comme le nom table apparaît dans des contextes comptable, il serait classé en temps que nom comptable)
\item classifier le contexte seul sans regarder le nom à classer
\item classifier le contexte en utilisant aussi des informations lexicales du mot (éventuellement utilisé la classe du nom hors contexte)
\end{itemize}

Je vais par la suite entrer plus en détail sur les motivations de chacune de ces approches et expliquer les différentes implémentations.

\subsection{Classifieur lexical}

 Nous avons tout d'abord pensé à classifié les mots hors contexte et à appliquer la classe prédite à tout les contexte où ce mot apparaît. Nous pensions que ça permettrait d'avoir une première baseline assez rapidement, car la grande partie des mots sont soit très majoritairement massifs soit très majoritairement comptable, de plus c'est une information que nous pensons utile pour la suite en particulier pour la dernière approche. 
 	\subsubsection*{Word Embedding}
  Nous avons tout d'abord pensé à utilisé des word embedding qui sont une représentation vectorielle des mots calculer à l'aide des contextes où les mots apparaissent. Cette représentation à la particularité que les mots apparaissant dans des contextes similaires possèdent des vecteurs proches, ce type de représentation semble donc utile pour notre tache de classification. Nous avons donc calculé les word embedding des mots de tout le frWaC, à l'aide de la bibliothèque Python Gensim avec comme paramètres :

\begin{itemize}
\item une taille de 200, ce qui est une taille standard
\item un fenêtre de 2, c'est à dire que pour l'on créer les word embeddings en prenant comme contexte deux mots avant et deux mots après
\item skip-gram comme modèle pour apprendre les embeddings\\
\end{itemize}

Nous avons ensuite entraîner un classifieur KNN (Méthode des k plus proches voisins) implémenté dans la librairie Python Scikit-Learn sur les word embeddings des 100 mots massifs et les 100 mots comptables de nos données d'apprentissage. Le nombre k de voisins est déterminé à l'aide d'une validation croisé sur l'ensemble d'entraînement.\\

Ce système a été évalué de deux manières :
\begin{itemize}
\item Nous avons classé les 100 mots comptables et les 100 mots massifs de test, cela donne une précision de 90,3\%, cependant il s'agit de mot que l'on considère "facile" à classer.
\item Nous avons classé les 100 noms que nous avons choisis aléatoirement et appliqué leur classe prédite à toutes les phrases annoté et calculé la précision en fonction de l'annotation, ce qui donne 68,6\% de réussite.\\
\end{itemize}

Nous avons testé une autre approche qui consiste pour chaque mot que l'on souhaite classer à faire la moyenne des cosinus pour tout les mots comptable et massifs de l'entraînement et de la classer dans la classe ayant la plus grande moyenne. L'évaluation est faite de la même manière que précédemment est les résultats sont :
\begin{itemize}
\item 85\% sur les listes de mots massifs et comptables hors contexte.
\item 66,9\% sur les phrases annotées. \\
\end{itemize}

Cette approche ne s'avère pas concluante, cela est du au peu de données d'apprentissage, en effet les points les plus proches peuvent être en réalité très éloignés, de plus les word embeddings ne sont pas calculé pour cette tâche en particulier, ils ont donc des informations non utile et deux mots peuvent être proches car leur sens est proche (ils apparaissent donc dans des contextes semblables) mais leurs classes peuvent être différentes. C'est pour cela que nous avons décidé d'abandonner les word embeddings\\

 	\subsubsection*{Nom à trouver}

Nous avons ensuite décidé d'utiliser le classifieur de contexte (nous reviendrons sur ce classifieur dans la section 4.2) pour donner un score de massivité aux lemmes. Ce classifieur nous donne un score de massivité associé à un certain contexte, pour un lemme donné nous faisons la moyenne des scores de massivité pour tout les contextes où il apparaît. Ce score de massivité est un score entre 0 et 1, on considère que si ce score est supérieur à 0.5, le mot est massif, s'il est inférieur à 0.5 le mot est comptable.
Cette approche donne les résultats suivants : \\
\#TODO

\subsection{Classifieur de contexte}
 	\subsubsection*{Réseau de neurones}


\subsection{Classifieur final}


\section{Autres applications}


\section{Résultats}

\section{Pistes pour la suite}

\section*{Bibliographie}

\section{Consignes}

Ins\'erer ici le texte du rapport dans le format et la structure que
vous voulez.


N'oubliez pas de mettre \`a la fin du rapport la bibliographie.

\bigskip

Une fois que votre rapport est pr\^et, produisez-en une version
pdf. Relisez-la avec attention. V\'erifiez qu'il n'y a pas de
probl\`emes d'accentuation.



\bigskip

Merci d'avoir bien voulu suivre ces instructions.

\end{document}

